AI Is Eating Data Center Power Demand—and It’s Only Getting Worse | WIRED
Skip to main content
Open Navigation Menu
Menu
AI Is Eating Data Center Power Demand—and It’s Only Getting Worse
Security
Politics
The Big Story
Business
Science
Culture
Ideas
Merch
Reviews
More
Chevron
Search
Search
Security
Politics
The Big Story
Business
Science
Culture
Ideas
Merch
Reviews
Podcasts
Video
Newsletters
Magazine
Travel
Steven Levy's Plaintext Column
WIRED Classics from the Archive
Events
WIRED Insider
WIRED Consulting
Coupons
Molly Taft
Science
May 22, 2025 2:09 PM
AI Is Eating Data Center Power Demand—and It’s Only Getting Worse
A new analysis of AI hardware being produced and how it is being used attempts to estimate the vast amount of electricity being consumed by AI.
Photograph: halbergman/ Getty Images
Save this story
Save
Save this story
Save
AI’s energy use
already represents as much as 20 percent of global data-center power demand,
research published Thursday
in the journal Joule shows. That demand from
AI
, the research states, could double by the end of this year, comprising nearly half of all total data-center
electricity
consumption worldwide, excluding the electricity used for
bitcoin
mining.
The new research is published in a commentary by Alex de Vries-Gao, the founder of Digiconomist, a research company that evaluates the environmental impact of technology. De Vries-Gao started Digiconomist in the late 2010s to explore the impact of bitcoin mining, another extremely energy-intensive activity, would have on the environment. Looking at AI, he says, has grown more urgent over the past few years because of the widespread adoption of ChatGPT and other large language models that use massive amounts of energy. According to his research, worldwide AI energy demand is now set to surpass demand from bitcoin mining by the end of this year.
“The money that bitcoin miners had to get to where they are today is peanuts compared to the money that
Google
and
Microsoft
and all these big tech companies are pouring in [to AI],” he says. “This is just escalating a lot faster, and it’s a much bigger threat.”
The development of AI is already having an impact on Big Tech’s climate goals. Tech giants have
acknowledged in recent sustainability reports
that AI is largely responsible for driving up their energy use. Google’s greenhouse gas emissions, for instance, have increased 48 percent since 2019, complicating the company’s goals of reaching net zero by 2030.
“As we further integrate AI into our products, reducing emissions may be challenging due to increasing energy demands from the greater intensity of AI compute,” Google’s 2024 sustainability report
reads
.
Last month, the International Energy Agency released a
report
finding that data centers made up 1.5 percent of global energy use in 2024—around 415 terrawatt-hours, a little less than the yearly energy demand of Saudi Arabia. This number is only set to get bigger: Data centers’ electricity consumption has grown four times faster than overall consumption in recent years, while the amount of investment in data centers has nearly doubled since 2022, driven largely by massive expansions to account for new AI capacity. Overall, the IEA predicted that data center electricity consumption will grow to more than 900 TWh by the end of the decade.
But there’s still a lot of unknowns about the share that AI, specifically, takes up in that current configuration of electricity use by data centers. Data centers power a variety of services—like hosting cloud services and providing online infrastructure—that aren’t necessarily linked to the energy-intensive activities of AI. Tech companies, meanwhile, largely keep the energy expenditure of their software and hardware private.
Some attempts to quantify AI’s energy consumption have started from the user side: calculating the amount of electricity that goes into a single ChatGPT search, for instance. De Vries-Gao decided to look, instead, at the supply chain, starting from the production side to get a more global picture.
The high computing demands of AI, De Vries-Gao says, creates a natural “bottleneck” in the current global supply chain around AI hardware, particularly around the Taiwan Semiconductor Manufacturing Company (TSMC), the undisputed leader in producing key hardware that can handle these needs. Companies like Nvidia outsource the production of their chips to TSMC, which also produces chips for other companies like Google and AMD. (Both TSMC and Nvidia declined to comment for this article.)
De Vries-Gao used analyst estimates, earnings call transcripts, and device details to put together an approximate estimate of TSMC’s production capacity. He then looked at publicly available electricity consumption profiles of AI hardware and estimates on utilization rates of that hardware—which can vary based on what it’s being used for—to arrive at a rough figure of just how much of global data-center demand is taken up by AI. De Vries-Gao calculates that without increased production, AI will consume up to 82 terrawatt-hours of electricity this year—roughly around the same as the annual electricity consumption of a country like Switzerland. If production capacity for AI hardware doubles this year, as analysts have projected it will, demand could increase at a similar rate, representing almost half of all data center demand by the end of the year.
Despite the amount of publicly available information used in the paper, a lot of what De Vries-Gao is doing is peering into a black box: We simply don’t know certain factors that affect AI’s energy consumption, like the utilization rates of every piece of AI hardware in the world or what machine learning activities they’re being used for, let alone how the industry might develop in the future.
Sasha Luccioni, an AI and energy researcher and the climate lead at open-source machine-learning platform Hugging Face, cautioned about leaning too hard on some of the conclusions of the new paper, given the amount of unknowns at play. Luccioni, who was not involved in this research,
says
that when it comes to truly calculating AI’s energy use, disclosure from tech giants is crucial.
“It’s because we don’t have the information that [researchers] have to do this,” she says. “That’s why the error bar is so huge.”
And tech companies
do
keep this information. In 2022, Google published a paper on machine learning and electricity use,
noting
that machine learning was “10%–15% of Google’s total energy use” from 2019 to 2021, and predicted that with best practices, “by 2030 total carbon emissions from training will reduce.” However, since that paper—which was released before Google Gemini’s debut in 2023—Google has not provided any more detailed information about how much electricity ML uses. (Google declined to comment for this story.)
“You really have to deep-dive into the semiconductor supply chain to be able to make any sensible statement about the energy demand of AI,” De Vries-Gao says. “If these big tech companies were just publishing the same information that Google was publishing three years ago, we would have a pretty good indicator” of AI’s energy use.
You Might Also Like …
In your inbox:
Upgrade your life with
WIRED-tested gear
“Wi-Fi keeps going down”
: Trump’s RTO mandate is going terribly
Big Story:
The worm that
no computer scientist can crack
Yuval Noah Harari
: “Prepare to share the planet with AI superintelligence”
Uncanny Valley:
An insider look at
the influence of Silicon Valley
Molly Taft
is a senior writer for WIRED, covering climate change, energy, and the environment. Previously, they were a reporter and editor at Drilled, an investigative climate multimedia reporting project. Before that, they wrote about climate change and technology for Gizmodo, and served as a contributing editor for the New ...
Read more
Senior Writer, Climate
Topics
science
environment
artificial intelligence
Energy
electricity
Read More
These Startups Are Building Advanced AI Models Without Data Centers
A new crowd-trained way to develop LLMs over the internet could shake up the AI industry with a giant 100 billion-parameter model later this year.
Will Knight
The Dream of the Metaverse Is Dying. Manufacturing Is Keeping It Alive
Forget Mark Zuckerberg’s vision of VR meetings; the industrial metaverse bridges digital and physical worlds in a way that’s actually useful.
Nicole Kobie
Google DeepMind’s AI Agent Dreams Up Algorithms Beyond Human Expertise
A new system that combines Gemini’s coding abilities with an evolutionary approach improves data center scheduling and chip design, and fine-tunes large language models.
Will Knight
The Middle East Has Entered the AI Group Chat
The UAE and Saudi Arabia are investing billions in US AI infrastructure. The deals could help the US in the AI race against China.
Will Knight
States and Startups Are Suing the US Nuclear Regulatory Commission
Critics of the NRC say its red tape and lengthy authorization timelines stifle innovation, but handing some of its responsibilities to states could undermine public trust and the industry’s safety record.
Molly Taft
Singapore’s Vision for AI Safety Bridges the US-China Divide
In a rare moment of global consensus, AI researchers from the US, Europe, and Asia came together in Singapore to form a plan for researching AI risks.
Will Knight
Jack Dorsey's Block Made an AI Agent to Boost Its Own Productivity
Jack Dorsey’s company went all-in on agents by deploying one capable of building software—and occasionally deleting stuff.
Will Knight
DOGE Used a Meta AI Model to Review Emails From Federal Workers
DOGE tested and used Meta’s Llama 2 model to review and classify responses from federal workers to the infamous “Fork in the Road” email.
Makena Kelly
A United Arab Emirates Lab Announces Frontier AI Projects—and a New Outpost in Silicon Valley
As Donald Trump pens deals in the Middle East, the gulf nation opens a research lab in San Francisco.
Will Knight
Behold the Social Security Administration’s AI Training Video
Social Security workers are being asked to use an AI chatbot. An animated video on how to do so failed to mention that the chatbot can’t be trusted with personally identifiable information.
David Gilbert
Kentucky’s Bitcoin Boom Has Gone Bust
In the US state's coal country, crypto mining was supposed to bring renewal. Now mines are powering down, and investors are hoping AI-powered data centers will fill the void.
Dina Temple-Raston
The Agonizing Task of Turning Europe’s Power Back On
A massive blackout affecting Spain, Portugal, and parts of France has been blamed on atmospheric conditions. Now engineers face the arduous task of getting the power back on.
Natasha Bernal
WIRED is where tomorrow is realized. It is the essential source of information and ideas that make sense of a world in constant transformation. The WIRED conversation illuminates how technology is changing every aspect of our lives—from culture to business, science to design. The breakthroughs and innovations that we uncover lead to new ways of thinking, new connections, and new industries.
More From WIRED
Subscribe
Newsletters
FAQ
WIRED Staff
WIRED Education
Editorial Standards
Archive
RSS
Accessibility Help
Reviews and Guides
Reviews
Buying Guides
Mattresses
Electric Bikes
Soundbars
Streaming Guides
Wearables
TVs
Coupons
Gift Guides
Advertise
Contact Us
Manage Account
Jobs
Press Center
Condé Nast Store
User Agreement
Privacy Policy
Your California Privacy Rights
©
2025
Condé Nast. All rights reserved.
WIRED
may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices
Select international site
United States
LargeChevron
Italia
Japón
Czech Republic & Slovakia
Facebook
X
Pinterest
YouTube
Instagram
Tiktok